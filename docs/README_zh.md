# Mobile Use ğŸ“±
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

<h2 style="text-align: center;">Mobile Useâ€‹: Automate your mobile with AI - Any app, any task.</h2>

![](assets/framework.png)

[ ä¸­æ–‡ | [English](../README.md) ]

https://github.com/user-attachments/assets/7cd023b6-816f-4514-93cc-62bcb1d888c5

ç”¨æˆ·åœ¨ Web ç•Œé¢è¾“å…¥è‡ªç„¶äººè¯­è¨€æŒ‡ä»¤ï¼ŒMobile Use çš„ GUI æ™ºèƒ½ä½“è‡ªåŠ¨æ“ä½œæ‰‹æœºå¹¶å®Œæˆä»»åŠ¡ã€‚


## ğŸ“Š Benchmark
![](assets/benchmark.png)

æˆ‘ä»¬åœ¨ [AndroidWord](https://github.com/google-research/android_world) åŠ¨æ€æµ‹è¯„ç¯å¢ƒä¸­è¯„ä¼°äº† Mobile Use çš„æ™ºèƒ½ä½“æ–¹æ¡ˆï¼ˆè§†è§‰æ¨¡å‹ä½¿ç”¨ Qwen2.5-VL-72Bï¼‰ï¼Œè·å¾— 38% çš„æˆåŠŸç‡ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§
- **è‡ªåŠ¨æ“ä½œæ‰‹æœº**ï¼šåŸºäºç”¨æˆ·çš„è¾“å…¥ä»»åŠ¡æè¿°ï¼Œè‡ªåŠ¨æ“ä½œUIå®Œæˆä»»åŠ¡
- **æ™ºèƒ½å…ƒç´ è¯†åˆ«**ï¼šè§£æGUIå¸ƒå±€å¹¶å®šä½æ“ä½œç›®æ ‡
- **å¤æ‚ä»»åŠ¡å¤„ç†**ï¼šæ”¯æŒå¤æ‚æŒ‡ä»¤åˆ†è§£å’Œå¤šæ­¥æ“ä½œ


<!-- ## ğŸ› ï¸ æŠ€æœ¯æ¶æ„ -->


## ğŸš€ å¿«é€Ÿå¼€å§‹
### å‰ç½®è¦æ±‚
#### 1. Python 3.10+

#### 2. å¯ç”¨å¼€å‘è€…æ¨¡å¼å¹¶æ‰“å¼€æ‰‹æœºä¸Šçš„USBè°ƒè¯•
<img src="assets/usb_debug_zh.png" style="width:30%; height:auto;">

#### 3. å®‰è£… SDK Platform-Tools å·¥å…·
- Step 1. ä¸‹è½½ SDK Platform-Tools å·¥å…·, ç‚¹å‡» [è¿™é‡Œ](https://developer.android.com/tools/releases/platform-tools#downloads).
- Step 2. è§£å‹æ–‡ä»¶å¹¶å°† `platform-tools` è·¯å¾„æ·»åŠ è‡³ç¯å¢ƒå˜é‡.
![alt text](assets/adb_tool.png)
- Step 3. æ‰“å¼€å‘½ä»¤è¡Œï¼Œè¾“å…¥ `adb devices` (Windows: `adb.exe devices`) éªŒè¯ adb æ˜¯å¦å¯ç”¨
- Step 4. é€šè¿‡USBçº¿è¿æ¥ç”µè„‘å’Œæ‰‹æœº


### å®‰è£…æŒ‡å—
> `mobile-use` éœ€è¦ä½¿ç”¨ [adb](https://developer.android.com/tools/adb) æ¥æ§åˆ¶æ‰‹æœºï¼Œéœ€è¦é¢„å…ˆå®‰è£…ç›¸å…³å·¥å…·å¹¶ä½¿ç”¨USBè¿æ¥æ‰‹æœºå’Œç”µè„‘ã€‚

#### 1. å…‹éš†é¡¹ç›®
```
git clone https://github.com/MadeAgents/mobile-use
```

#### 2. å®‰è£…ä¾èµ–
```
pip install .
```

#### 3. éªŒè¯ adb æ˜¯å¦å·²è¿æ¥
åœ¨å‘½ä»¤è¡Œç»ˆç«¯æ‰§è¡Œ `adb devices` ï¼ˆWindowsï¼š`adb.exe devices`ï¼‰å‘½ä»¤ï¼Œå¦‚æœåˆ—å‡ºè®¾å¤‡å·è¡¨ç¤ºå·²è¿æ¥æˆåŠŸï¼Œæ­£ç¡®çš„æ—¥å¿—å¦‚ä¸‹ï¼š
```
List of devices attached
a22d0110        device
```

#### 4. å¯åŠ¨æœåŠ¡
```
python webui.py
```

### ä½¿ç”¨æ–¹å¼
å¾…æœåŠ¡å¯åŠ¨æˆåŠŸä¹‹åï¼Œåœ¨æµè§ˆå™¨æ‰“å¼€åœ°å€ï¼šhttp://127.0.0.1:7860ï¼Œå³å¯è¿›å…¥åˆ° WebUI é¡µé¢ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](assets/webui.png)

ç‚¹å‡» VLM Configuration è®¾ç½®å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ Base URL å’Œ API Keyï¼Œæ¨èä½¿ç”¨ Qwen2.5-VL ç³»åˆ—çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚

![alt text](assets/vlm_configuration.png)


åœ¨å·¦ä¸‹æ–¹çš„è¾“å…¥æ¡†è¾“å…¥ä»»åŠ¡æè¿°ï¼Œç‚¹å‡»å¼€å§‹å³å¯æ‰§è¡Œä»»åŠ¡ã€‚


## ğŸ‰ More Demo
Case1ï¼šSearch the latest news of DeepSeek-R2 in Xiaohongshu APP and forward one of the news to the Weibo App

https://github.com/user-attachments/assets/c44ddf8f-5d3f-4ace-abb3-fab4838b68a4


Case2ï¼šOrder 2 Luckin coffees with Meituan, 1 hot raw coconut latte standard sweet, and 1 cold light jasmine

https://github.com/user-attachments/assets/6130e87e-dd07-4ddf-a64d-051760dbe6b3


Case3ï¼šç”¨ç¾å›¢ç‚¹ä¸€æ¯å’–å•¡ï¼Œå†°çš„ï¼Œæ ‡å‡†ç³–

https://github.com/user-attachments/assets/fe4847ba-f94e-4baa-b4df-857cadae5b07


Case4ï¼šç”¨ç¾å›¢å¸®æˆ‘ç‚¹2æ¯ç‘å¹¸å’–å•¡ï¼Œè¦ç”Ÿæ¤°æ‹¿é“æ ‡å‡†ç³–ã€çƒ­çš„

https://github.com/user-attachments/assets/5c4d3ce8-0135-4e6e-b003-b20f81f834d4


Case5ï¼šåœ¨æµè§ˆå™¨æ‰¾ä¸€å¼ OPPO Find N5å›¾ç‰‡ï¼Œè¯¢é—®DeepSeekåº”ç”¨è¯¥æ‰‹æœºä»‹ç»ä¿¡æ¯ï¼Œå°†æ‰¾åˆ°çš„å›¾ç‰‡å’Œä»‹ç»ä¿¡æ¯é€šè¿‡å°çº¢ä¹¦å‘å¸ƒ

https://github.com/user-attachments/assets/4c3d8800-78b7-4323-aad2-8338fe81cb81


Case6ï¼šå¸®æˆ‘å»OPPOå•†åŸã€äº¬ä¸œã€ä»¥åŠæ·˜å®åˆ†åˆ«çœ‹ä¸€ä¸‹oppofind n5å”®ä»·æ˜¯å¤šå°‘

https://github.com/user-attachments/assets/84990487-f2a3-4921-a20e-fcdebfc8fc60


## âš™ï¸ é«˜çº§ç”¨æ³•

### æ›´å¤šå‚æ•°é…ç½®
**ğŸ“± Mobile Settings**
é€šè¿‡ `Android ADB Server Host` å’Œ `Android ADB Server Port` å¯ä»¥æŒ‡å®š Android ADB æœåŠ¡çš„åœ°å€å’Œç«¯å£ï¼Œå¯ç”¨äºè¿œç¨‹è®¾å¤‡è¿æ¥æˆ–è€…æœ¬åœ°éé»˜è®¤ç«¯å£çš„ Android ADB æœåŠ¡ã€‚å½“å­˜åœ¨å¤šå°è®¾å¤‡æ—¶ï¼Œéœ€è¦é€šè¿‡ `Device Serial No.` æŒ‡å®šä½¿ç”¨é‚£ä¸€å°è®¾å¤‡ã€‚`Reset to HOME` å‚æ•°è¡¨ç¤ºæ‰§è¡Œä»»åŠ¡æ—¶æ˜¯å¦å°†æ‰‹æœºè¿”å›åˆ°ä¸»é¡µå†æ‰§è¡Œï¼Œå¦‚æœæ—¶ç»§ç»­ä¸Šä¸€ä¸ªä»»åŠ¡ï¼Œåˆ™éœ€è¦å–æ¶ˆè¯¥é€‰é¡¹ã€‚

![alt text](assets/mobile_settings.png)

**âš™ï¸ Agent Settings**

`Max Run Steps` å‚æ•°æ˜¯æŒ‡å®š Agent æœ€å¤§è¿­ä»£æ­¥æ•°ï¼Œå½“å‰ä»»åŠ¡è¶…å‡ºæœ€å¤§è¿­ä»£æ­¥æ•°æ—¶ï¼Œä»»åŠ¡å°†è¢«åœæ­¢ã€‚å› æ­¤ï¼Œå¯¹äºè¾ƒæ“ä½œæ­¥æ•°è¾ƒå¤šçš„å¤æ‚ä»»åŠ¡ï¼Œå»ºè®®è®¾ç½®è¾ƒå¤§å€¼ã€‚`Maximum Latest Screenshot` æ˜¯æ§åˆ¶ Agent èƒ½å¦çœ‹åˆ°çš„æœ€æ–°å±å¹•æˆªå›¾æ•°é‡ï¼Œç”±äºå›¾ç‰‡æ¶ˆè€—è¾ƒå¤šTokenï¼Œå› æ­¤å½“ä»»åŠ¡æ­¥æ•°è¾ƒå¤šæ—¶ï¼Œé€‚å½“å–æœ€æ–°çš„ `Maximum Latest Screenshot` å¼ æˆªå›¾å‘ç»™ VLM ç”Ÿæˆä¸‹ä¸€æ­¥æ“ä½œç›¸åº”ã€‚`Maximum Reflection Action` åˆ™æ˜¯æ§åˆ¶ Agent åæ€çš„æœ€å¤§æ¬¡æ•°ï¼Œå…¶å€¼è¶Šå¤§ï¼ŒAgent çš„å®¹é”™ç‡å°±è¶Šé«˜ï¼Œä½†åŒæ—¶å¤„ç†ä»»åŠ¡çš„è€—æ—¶ä¹Ÿéšä¹‹è¶Šé•¿ã€‚é€šè¿‡ç‚¹å‡» **âš™ï¸ Agent Settings** é€‰é¡¹å¯ä»¥è®¾ç½®è¿™ä¸‰ä¸ªå‚æ•°çš„å€¼ï¼š

![alt text](assets/agent_settings.png)


**ğŸ”§ VLM Configuration**
ç‚¹å‡» `VLM Configuration` å¯æŒ‡å®šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ Base URL å’Œ API Keyï¼Œä»¥åŠæ¨¡å‹åç§°å’Œæ¸©åº¦ç³»æ•°ï¼Œæ¨èä½¿ç”¨ Qwen2.5-VL ç³»åˆ—çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚
![alt text](assets/vlm_configuration.png)

### åœ¨ Python è„šæœ¬ä¸­ä½¿ç”¨ Agent æ™ºèƒ½ä½“
```python
import os
from dotenv import load_dotenv
from mobile_use.scheme import AgentState
from mobile_use import Environment, VLMWrapper, Agent
from mobile_use.logger import setup_logger

load_dotenv()
setup_logger(name='mobile_use')

# Create environment controller
env = Environment(serial_no='a22d0110')
vlm = VLMWrapper(
    model_name="qwen2.5-vl-72b-instruct", 
    api_key=os.getenv('VLM_API_KEY'),
    base_url=os.getenv('VLM_BASE_URL'),
    max_tokens=128,
    max_retry=1,
    temperature=0.0
)

agent = Agent.from_params(dict(type='default', env=env, vlm=vlm, max_steps=3))

going = True
input_content = goal
while going:
    going = False
    for step_data in agent.iter_run(input_content=input_content):
        print(step_data.action, step_data.thought)
```

### åˆ›å»ºå®šåˆ¶åŒ– Agent

é€šè¿‡ç»§æ‰¿ `Agent` å¹¶å®ç° `step` å’Œ `iter_run` æ–¹æ³•æ¥å®šä¹‰è‡ªå®šä¹‰ Agentã€‚

```python
from mobile_use.scheme import StepData
from mobile_use.utils import encode_image_url
from mobile_use.agents import Agent
from mobile_use.agents.agent import parse_reason_and_action

from typing import Iterator


SYSTEM_PROMPT = """
You are a GUI agent. You are given a task and your action history, with screenshots. You need to perform the next action to complete the task. 

## Output Format
```\nThought: ...
Action: ...\n```

## Action Space
click(point='(x1,y1)')
long_press(point='(x1,y1)')
type(text='')
scroll(start_point='(x1,y1)', end_point='(x3,y3)')
press_home()
press_back()
finished() # Submit the task regardless of whether it succeeds or fails.
call_user(question='') # Submit the task and call the user when the task is unsolvable, or when you need the user's help.
"""


@Agent.register('custom')
class CustomAgent(Agent):

    def reset(self, *args, **kwargs) -> None:
        """Reset Agent to init state"""
        self._init_data(**kwargs)

    def step(self, **kwargs) -> Iterator[StepData]:
        """Get the next step action based on the current environment state.

        Returns: The content is an iterator for StepData
        """
        # Init messages
        if self.curr_step_idx == 0:
            self.messages.extend([
                {'role': 'system', 'content': SYSTEM_PROMPT},
                {'role': 'user', 'content': f'Task goal description: {self.goal}'},
            ])

        # Get the current environment screen
        env_state = self.env.get_state()
        pixels = env_state.pixels.copy()
        pixels.thumbnail((1024, 1024))
 
        # Add new step data
        step_data = StepData(
            step_idx=self.curr_step_idx,
            curr_env_state=env_state,
            vlm_call_history=[]
        )
        self.trajectory.append(step_data)

        self.messages.append({
                'role': 'user', 
                'content': [
                    {'type': 'text', 'text': 'The mobile screenshot:'},
                    {"type": "image_url", "image_url": {"url": encode_image_url(pixels)}}
                ]
        })

        response = self.vlm.predict(self.messages, stream=False)
        step_data.content = response.choices[0].message.content
        reason, action = parse_reason_and_action(step_data.content, pixels.size, env_state.pixels.size)
        step_data.thought = reason
        step_data.action = action

        self.env.execute_action(action)

    def iter_run(self, input_content: str, stream: str=False) -> Iterator[StepData]:
        """Execute all step with maximum number of steps base on user input content.

        Returns: The content is an iterator for StepData
        """
        self.goal = input_content
        for step_idx in range(self.curr_step_idx, self.max_steps):
            self.curr_step_idx = step_idx
            for step_data in self.step(stream=stream):
                yield step_data
```

å®ä¾‹åŒ–å®šåˆ¶ Agent
```python
agent = Agent.from_params(dict(type='custom', env=env, vlm=vlm, max_steps=3))
```


## ğŸŒ± å‚ä¸è´¡çŒ®
æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼è¯·é˜…è¯»è´¡çŒ®æŒ‡å—äº†è§£ï¼š
- å¦‚ä½•æäº¤issueæŠ¥å‘Šé—®é¢˜
- å‚ä¸åŠŸèƒ½å¼€å‘çš„æµç¨‹
- ä»£ç é£æ ¼å’Œè´¨é‡æ ‡å‡†
- æ–‡æ¡£æ”¹è¿›å»ºè®®æ–¹å¼


## ğŸ“œ è®¸å¯åè®®
æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œå…è®¸è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹ä»£ç ï¼Œä½†éœ€ä¿ç•™åŸå§‹ç‰ˆæƒå£°æ˜ã€‚


## ğŸ“š å¼•ç”¨
å¦‚æœæ‚¨åœ¨æ‚¨çš„ç ”ç©¶æˆ–å·¥ä½œä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š
```
@software{
  title = {Mobile Useâ€‹: Automate your mobile with AI - Any app, any task.},
  author = {Jiamu Zhou, Xiaoyun Mo, Ning Li, Qiuying Peng},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/MadeAgents/mobile-use}
}
```

## ğŸ¤ è‡´è°¢
æœ¬é¡¹ç›®å¾—ç›Šäºï¼š
- çµæ„Ÿæ¥è‡ª [browser-use](https://github.com/browser-use/browser-use)
- æ™ºèƒ½ä½“çš„å¤§æ¨¡å‹æ˜¯åŸºäº [Qwen2.5-VL](https://huggingface.co/collections/Qwen/qwen25-vl-6795ffac22b334a837c0f9a5)
- Web UI æ˜¯åŸºäº [Gradio](https://www.gradio.app)

æ„Ÿè°¢ä»–ä»¬çš„ç²¾å½©å·¥ä½œã€‚
